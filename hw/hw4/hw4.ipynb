{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# initializing otter-grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4: Principal Component Analysis\n",
    "\n",
    "In lecture we discussed how PCA can be used for dimensionality reduction. Specifically, given a high-dimensional dataset, PCA allows us to:\n",
    "1. Understand the rank of the data. If $k$ principal components capture almost all of the variance, then the data is effectively rank $k$.\n",
    "2. Create 2D scatterplots of the data. Such plots are a rank 2 representation of our data, and allow us to visually identify clusters of similar observations.\n",
    "\n",
    "A solid geometric understanding of PCA will help you understand why PCA is able to do these  things. In this homework, we'll build that geometric intuition, and will also look at PCA on different datasets.\n",
    "\n",
    "### Due Date\n",
    "\n",
    "This assignment is due **Sunday 5/17 at 11:59pm PST**.\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import altair as alt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you run this notebook, you'll need to install a visualization package called plotly. To do so, you need to run the following command **only once**:\n",
    "```\n",
    "!pip install plotly\n",
    "```\n",
    "\n",
    "Paste and run the following command in the cell below and once the package is installed, you can delete the `pip` command and import `plotly` as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Note: If you're having problems with the 3d scatter plots, \n",
    "# uncomment the two lines below, and you should see a version that \n",
    "#      number that is at least 4.1.1.\n",
    "# import plotly\n",
    "# plotly.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: PCA on 3D Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In question 1, our goal is to see visually how PCA is simply the process of rotating the coordinate axes of our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reads in a 3D dataset. We have named the variable `surfboard` because the data resembles a surfboard when plotted in 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surfboard = pd.read_csv(\"data3d.csv\")\n",
    "surfboard.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will allow you to view the data as a 3d scatterplot. Rotate the data around and zoom in and out using your trackpad or the controls at the top right of the figure.\n",
    "\n",
    "You should see that the data is an ellipsoid that looks roughly like a surfboard or a [hashbrown patty](https://www.google.com/search?q=hashbrown+patty&source=lnms&tbm=isch). That is, it is pretty long in one direction, pretty wide in another direction, and relatively thin along its third dimension. We can think of these as the \"length\", \"width\", and \"thickness\" of the surfboard data.\n",
    "\n",
    "Observe that the surfboard is not aligned with the x/y/z axes.\n",
    "\n",
    "If you get an error that your browser does not support webgl, you may need to restart your kernel and/or browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(surfboard, x='x', y='y', z='z', range_x = [-10, 10], range_y = [-10, 10], range_z = [-10, 10])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give the figure a little more visual pop, we will create a separate dataframe where we'll add pre-determined color values (that we've arbitrarily chosen) to each point. These colors do not mean anything important, they're simply there as a visual aid.\n",
    "\n",
    "We will use `colorized_surfboard` only for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_colors = pd.read_csv(\"surfboard_colors.csv\", header = None).values\n",
    "colorized_surfboard = surfboard.copy()\n",
    "colorized_surfboard.insert(loc = 3, column = \"color\", value = s_colors)\n",
    "colorized_surfboard.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give the figure a little more visual pop, the following cell does the same plot, but now uses `colorized_surfboard` to display the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(colorized_surfboard, x='x', y='y', z='z', range_x = [-10, 10], range_y = [-10, 10], range_z = [-10, 10], color = \"color\", color_continuous_scale = 'RdBu')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 1a: center the data\n",
    "\n",
    "Now that we've understood the data, let's work on understanding what PCA will do when applied to this data.\n",
    "\n",
    "If you consult [Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis), you'll see that \"the original data is normalized before performing the PCA. The normalization of each attribute consists of *mean centering* â€“ subtracting each data value from its variable's measured mean so that its empirical mean (average) is zero. Some fields, in addition to normalizing the mean, do so for each variable's variance (to make it equal to 1)...\"(*Retireved May 2020*).\n",
    "\n",
    "For this exercise, we will not be scaling the variables, so that we can see how to compute the total variance from the singular values.\n",
    "\n",
    "To properly perform PCA, we will first need to \"center\" the data so that the mean of each feature is 0. \n",
    "\n",
    "Compute the columnwise mean of `surfboard` in the cell below, and store the result in `surfboard_mean`. You can choose to make `surfboard_mean` a numpy array or a series, whichever is more convenient for you. Regardless of what data type you use, `surfboard_mean` should have **3 means**, 1 for each attribute, with the `x` coordinate first, then `y`, then `z`.\n",
    "\n",
    "Then, subtract `surfboard_mean` from `surfboard`, and save the result in `surfboard_centered`. The order of the columns in `surfboard_centered` should be `x` first, then `y`, then `z`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfboard_mean = ...\n",
    "surfboard_centered = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 1b: SVD\n",
    "\n",
    "As you may recall from lecture, PCA is a specific application of the singular value decomposition (SVD) for matrices. If we have a data matrix $X$, we can decompose it into $U$, $\\Sigma$ and $V^T$ such that $X = U \\Sigma V^T$. Here, $U$ is the left singular vectors, $\\Sigma$ is a diagonal matrix containing the singular values, and $V^T$ are the right singular vectors.\n",
    "\n",
    "In the following cell, use the [`np.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) function to compute the SVD of `surfboard_centered`. Store the left singular vectors, singular values, and right singular vectors in `u`, `s`, and `vt` respectively. This is one line of simple code, exactly like what we saw in lecture.\n",
    "\n",
    "**Hint:** Set the `full_matrices` argument of `np.linalg.svd` to `False`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u, s, vt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1c: Total Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider the relationship between the singular values `s` and the variance of our data. Recall that the total variance is the sum of the variances of each column of our data. Below, we provide code that computes the variance for each column of the data.\n",
    "\n",
    "Note: The variances are the same for both `surfboard_centered` and `surfboard`, so we show only one to avoid redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(surfboard, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total variance of our dataset is given by the sum of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance_computed_from_data = sum(np.var(surfboard, axis=0))\n",
    "total_variance_computed_from_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As discussed in lecture, the total variance of the data is also equal to the sum of the squares of the singular values divided by the number of data points, that is:\n",
    "\n",
    "$$Var(X) = \\frac{\\sum_{i=1}^d{s_i^2}}{N}$$\n",
    "\n",
    "In the cell below, compute the total variance using the the formula above and store the result in the variable `total_variance_computed_from_singular_values`. Your result should be very close to `total_variance_computed_from_data`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_variance_computed_from_singular_values = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1d: Explained Variance and Scree Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, set `variance_explained_by_1st_pc` to the proportion of the total variance explained by the 1st principal component. Your answer should be a number between 0 and 1. \n",
    "\n",
    "Note: This topic was discussed in lecture.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained_by_1st_pc = ...\n",
    "variance_explained_by_1st_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can also create a scree plot that shows the variance explained by all of our principal components, ordered from most to least. Here the y-axis is the amount of variance explained by the ith principal component.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1-viz\n",
    "points: 3\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explained_var = pd.DataFrame({\n",
    "    'PC #': [1, 2, 3], \n",
    "    'Fraction of Variance Explained' : ...\n",
    "})\n",
    "\n",
    "# Draw your Altair visualization\n",
    "alt.Chart(explained_var, \n",
    "          title=\"Variance Explained by Principal Components\"\n",
    ").mark_bar(size=30).encode(\n",
    "    alt.X('...:O'),\n",
    "    alt.Y('...:Q')\n",
    ").configure_axisX(labelAngle=0).properties(width=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we divide by the total variance, we can get the fraction explained by each component. Note that the first y value is the same as what you computed earlier in this problem. \n",
    "\n",
    "Note: If you're wondering where `len(surfboard_centered)` went, it got canceled out when we divided the variance of a given PC by the total variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this small toy problem, the scree plot is not particularly useful. We'll see why they are useful in practice later in this homework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1e: V as a Rotation Matrix\n",
    "\n",
    "In lecture, we saw that the first column of $U \\Sigma$ contained the first principal component values for each observation, the second column of $U \\Sigma$ contained the second principal component values for each observation, and so forth.\n",
    "\n",
    "Let's give this matrix a name: $P = U \\Sigma$ is sometimes known as the \"principal component matrix\".\n",
    "\n",
    "The code below computes $P$ using $U$ and $\\Sigma$, then prints out the principal components for the 5th observation in the dataset.\n",
    "\n",
    "(Note the use of `@` to multiply two matrices in Python.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P = u @ np.diag(s)\n",
    "print(f\"The 5th observation in x/y/z is: {surfboard.iloc[4, 0]}, {surfboard.iloc[4, 1]}, {surfboard.iloc[4, 2]}\")\n",
    "print(f\"The 1st, 2nd, and 3rd pcs of our 5th observation are: {P[4, 0]}, {P[4, 1]}, {P[4, 2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in lecture how to interpret $V^T$, which is sometimes known as the \"mixing matrix\" or \"loadings matrix\". In the cell below, we show $V^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We know from discussion that $V^T$ gives us a way to convert our data into principal component values. For example, since the first row of $V^T$ is $[0.38, -0.67, -0.63]$, we have that:\n",
    "\n",
    "$$\\text{pc1} = 0.38x - 0.67y - 0.63z$$\n",
    "\n",
    "Thus for the 5th observation we get $2.21 = 0.39 \\cdot 1.95 - 0.67 \\cdot -0.19 - 0.63 \\cdot -2.1$.\n",
    "\n",
    "Another way to think about $V$ is that it is a rotation matrix that transforms our original data matrix $X$ (through rotation) into $P$. This is given by the simple relationship that $P = XV$, which we prove below:\n",
    "\n",
    "Proposition: $P = XV$\n",
    "\n",
    "Proof: \n",
    "\n",
    "1. Because $X = U \\Sigma V^T$, we have that $X = P V^T$.\n",
    "2. As mentioned in [lecture 10](https://drive.google.com/open?id=1_zgMHZ3IpJtBd3fe1j-TH9pkleAj8Okz), one special property of $V^T$ is that its inverse is also its transpose.\n",
    "3. Thus if we multiply both sides of $X = P V^T$, we get $XV = P V^T V$. Since $V^T V$ is the identity matrix, we have $XV = P$.\n",
    "\n",
    "In other words, another way to compute our principal component matrix $P$ is $P = XV$. In the cell below, compute $P$ using the original data and $V$. Assign the result to a variable called `surfboard_pcs`.\n",
    "\n",
    "*Hint*: In python, you can use `.T` to form the transpose of a numpy array. For example `u.T` is equivalent to saying $U^T$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1e\n",
    "points: 3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfboard_pcs = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Principal Component Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some sense, we can think of $P$ as an output of the PCA procedure. \n",
    "\n",
    "It is simply a rotation of the data such that the data will now appear \"axis aligned\". Specifically, for a 3d dataset, if we plot pc1, pc2, and pc3 along the x, y, and z axes of our plot, then the greatest amount of variation happens along the x axis, the second greatest amount along the y axis, and the smallest amount along the z axis. \n",
    "\n",
    "To visualize this, run the cell below, which will show our data now projected onto the principal component space. Compare with your original figure, and observe that the data is exactly the same, only it is now rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfboard_pcs = surfboard_pcs.rename(columns = {0: \"pc1\", 1: \"pc2\", 2: \"pc3\"})\n",
    "\n",
    "colorized_surfboard_pcs = surfboard_pcs.copy()\n",
    "colorized_surfboard_pcs.insert(loc = 3, column = \"color\", value = s_colors)\n",
    "colorized_surfboard_pcs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(colorized_surfboard_pcs, \n",
    "                    x='pc1', y='pc2', z='pc3', \n",
    "                    range_x = [-10, 10], range_y = [-10, 10], range_z = [-10, 10], \n",
    "                    color = 'color', color_continuous_scale = 'RdBu');\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in lecture that we created a scatter plot of only the first two principal components. \n",
    "We can do that here with our surfboard data as well.\n",
    "\n",
    "Note that the result is just the 3D plot as viewed from directly \"overhead\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = colorized_surfboard_pcs, \n",
    "                x = 'pc1', y = 'pc2', hue = \"color\", palette = \"RdBu\")\n",
    "plt.gca().set_xlim(-10, 10);\n",
    "plt.gca().set_ylim(-10, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we saw that the principal component matrix $P$ is simply the original data rotated in space so that it appears axis aligned.\n",
    "\n",
    "We also saw that $P$ can be computed as $P = U\\Sigma$ or as $P = XV$.\n",
    "\n",
    "Whenever we do a 2D scatter plot of only the first 2 columns of $P$, we are simply looking at the data from \"above\", i.e. so that the 3rd (or higher) PC is invisible to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "PCA really shines on data where you have reason to believe that the data is relatively low in rank. For example, in lecture, we looked at congressional votes -- the current high degree of political polarization means that congresspeople will mostly vote in line with their party. And indeed, we saw that the first principal component very strongly separated republicans from democrats.\n",
    "\n",
    "In this final question of the homework, we'll look at how states voted in presidential elections between 1972 and 2016. **Our ultimate goal in Question 2 is to show how 2D PCA scatterplots can allow us to identify clusters in a high dimensional dataset.** For this example, that means finding groups of states that vote similarly by plotting their 1st and 2nd principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2a: Get the source data \n",
    "\n",
    "Unlike prior assignments, we're going to make you go **get the data yourself**. Specifically, we'd like you to use this table from wikipedia: [https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state](https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state). \n",
    "\n",
    "You can convert the table into csv format this website: [https://wikitable2csv.ggor.de/](https://wikitable2csv.ggor.de/). Simply paste the URL of the URL into wikitable2csv and leave the default options as they are.\n",
    "\n",
    "Then click download on Table 1, and you should download a file called `table-1.csv`.\n",
    "\n",
    "Upload this file to your Jupyterhub folder (where this ipynb is) and rename it \"`presidential_elections.csv`\". Then run the cell below to make sure that you did everything properly.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"presidential_elections.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2b: Clean the data\n",
    "\n",
    "The data in this table is pretty messy. Create a clean version of this table called `df_1972_to_2016`. It should contain exactly 51 rows (corresponding to the 50 state plus Washington DC) and 12 columns (one for each of the election year from 1972 to 2016, to include only republican `R` and democratic `D` votes in each state).\n",
    "\n",
    "**The index** of this dataframe should be the state name. The name you pick for the index doesn't matter.\n",
    "\n",
    "**The column names** contain **only** the numerical values: i.e., only the *numerical value for the year*, NO extraneous symbols.\n",
    "\n",
    "*Hint*: Our solution uses `iloc`, `drop` (twice), `rename`, and `set_index`.\n",
    "\n",
    "*Note*: Feel free to open your csv file in Excel or Google Slides to explore the data if you find that easier. However, we require that you **do your actual data cleaning in pandas**, i.e. don't just delete and rename columns in Excel. \n",
    "\n",
    "*Note*: In your personal projects, it is sometimes more convenient to manually do your data cleaning using Excel or Google Sheets. The downside of doing this is that you have no record of what you did, and if you have to redownload the data, you have to redo the manual data cleaning process.\n",
    "\n",
    "*Hint*: It will be easiest for you to start by extracting the last 14 columns and begin cleaning from there (remember that Python allows negative indexing, which you can use in `iloc`).\n",
    "\n",
    "*Hint*: Remember that `.drop` allows you to drop rows as well as columns (using the `axis` parameter).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1972_to_2016 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2c: get numerical values\n",
    "\n",
    "To perform PCA, we need to convert our data into being numerical. To do this, replace all of the \"D\" characters with the number 0, and all of the \"R\" characters with the number 1. Store the resulting dataframe in a new variable `df_1972_to_2016_num`. \n",
    "\n",
    "*Hint:* Use `df.replace` (which by default *returns* the modified dataframe without affecting the original).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1972_to_2016_num = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2d: center and scale the data\n",
    "\n",
    "Now **center the data** so that the mean of each column is 0 and **scale the data** so that the variance of each column is 1. Store your result in `df_1972_to_2016`.\n",
    "\n",
    "*Hint*: Remember that `np.mean` and `np.std` allow you to use the `axis` parameter to compute the mean/standard deviation of the columns (instead of the flattened array).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1972_to_2016_centered = ...\n",
    "df_1972_to_2016_aligned = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2e: SVD\n",
    "\n",
    "We now have our data in a nice and tidy centered and scaled format, phew. We are now ready to do PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, **create a new dataframe** `first_2_pcs` that contains exactly the first two columns of the principal components matrix. The first column should be labeled `pc1` and the second column should be labeled `pc2`. Store your result in `first_2_pcs`.\n",
    "\n",
    "*Hint*: Just like you did before, use `np.linalg.svd`. **Do not overwrite** `u, s, vt` that you defined earlier, **use `u1, s1, vt1`** for the result of `np.linalg.svd`. \n",
    "\n",
    "*Hint*: You can use Python's slicing method to extract the first two columns.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2e\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#u1, s1, vt1 = ...\n",
    "first_2_pcs = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2f: plot the first two principal components\n",
    "\n",
    "The cell below plots the 1st and 2nd principal components of our 50 states + Washington DC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(first_2_pcs).mark_point().encode(\n",
    "    x = \"pc1\",\n",
    "    y = \"pc2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Unfortunately, we have two problems:\n",
    "\n",
    "1. There is a lot of overplotting, with only 27 distinct dots. This means that at least some states voted exactly alike in these elections.\n",
    "2. We don't know which state is which, because the points are unlabeled.\n",
    "\n",
    "Let's start by addressing problem 1. \n",
    "\n",
    "**In the cell below, create a new dataframe `first_2_pcs_jittered` with a small amount of random noise added to each principal component. In this same cell, create a scatterplot.**\n",
    "\n",
    "The amount of noise you add should not significantly affect the appearance of the plot, it should simply serve to separate overlapping observations.\n",
    "\n",
    "*Hint:* Use `np.random.normal` with the mean of 0 and a standard deviation of 0.1, and an appropriate value for the `size` parameter. Note that you want to *add a different value to each element* stored in the `first_2_pcs`, but you should avoid using loops and instead use the `size` parameter.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2f\n",
    "manual: true\n",
    "points: 3\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_2_pcs_jittered = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2g: visualize the data using the first principal components\n",
    "\n",
    "To label the points on a scatter plot of your **jittered data**, the best option is to use Altair's `mark_text()` and give it a list of state names as the `text` encoding. \n",
    "\n",
    "*Hint*: You can get a list of the state names with `list(df_1972_to_2016.index)`.\n",
    "\n",
    "Select **one option** from the two given below to create a scatter plot of your jittered data. (We recommend starting with Option 1 and getting it to work, and then, if you have time, come back to figure out Option 2.)\n",
    "\n",
    "\n",
    "**Option 1**: Altair will let you zoom and pan around to look at the data if you add the `.interactive()` at the end of the chart definition.\n",
    "\n",
    "**Option 2**: *Alternatively* (or \"additionally\", depending how curious you are), you can create a cool linked chart, which would automatically update the list of states whose names you have selected on the scatter plot. \n",
    "\n",
    "One important skill as a user of modern tools is using existing documentation and examples to get the plot you want. Using the example given on this page as a [guide](https://altair-viz.github.io/gallery/scatter_linked_table.html), create a scatter plot of your jittered presidential election data.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "*Workflow productivity hint*: Find a shortcut to quickly comment/uncomment a highlighted selection inside a code cell: at the top bar, go to `Help => Keyboard Shortcuts`, scroll to the section \"Edit Mode\" and find the shortcut for \"comment\" (note, it is the same shortcut to uncomment a selection).\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2gi\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names = ...\n",
    "first_2_pcs_jittered['state'] = ...\n",
    "\n",
    "###############################################\n",
    "\n",
    "### OPTION 1\n",
    "# alt.Chart(...).mark_text().encode( \n",
    "#     x = ...,\n",
    "#     y = ...,\n",
    "#     text = ...\n",
    "# ).properties(width=450)...\n",
    "\n",
    "###############################################\n",
    "### OPTION 2\n",
    "\n",
    "# # Brush for selection\n",
    "# brush = alt.selection(type='interval')\n",
    "\n",
    "# labels = alt.Chart(...).mark_text().encode(\n",
    "#     x = ...,\n",
    "#     y = ...,\n",
    "#     text = ...\n",
    "#     color=alt.condition(brush, alt.value('blue'), alt.value('grey'))\n",
    "# ).properties(width=450).add_selection(brush)\n",
    "\n",
    "\n",
    "# # Base chart for data tables\n",
    "# ranked_text = alt.Chart(first_2_pcs_jittered).mark_text().encode(\n",
    "#     y = ...\n",
    "# ).transform_window(\n",
    "#     row_number='row_number()'\n",
    "# ).transform_filter(\n",
    "#     brush\n",
    "# ).transform_window(\n",
    "#     rank='rank(row_number)'\n",
    "# ).transform_filter(\n",
    "#     alt.datum.rank<20\n",
    "# )\n",
    "\n",
    "# # Data Tables\n",
    "# origin = ranked_text.encode(text='state:N').properties(title='State', width=100)\n",
    "\n",
    "# # Build chart\n",
    "# alt.hconcat(\n",
    "#     ...,\n",
    "#     ...\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Give an example of a cluster of states that vote a similar way (remember what the 0 and 1 originally stood for?). Does the composition of this cluster surprise you? If you're not familiar with U.S. politics, it's fine to just say '*No, I'm not surprised because I don't know anything about U.S. politics.*'.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2gii\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, write down anything interesting that you observe by looking at this plot. You will get credit for this as long as you write something reasonable that you can take away from the plot.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2giii\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2h: plot the columns' contributions to PCs\n",
    "\n",
    "We can also look at the contributions of each year's elections results on the values for our principal components. Below, we will define and use the `plot_pc` function to plot the 1st row of $V^T$ in the cell below.\n",
    "\n",
    "Here by \"1st row\" we mean the row that is used to generate `pc1`, and by \"2nd row\" we mean the row that is used to generate `pc2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pc(col_names, vt, k):\n",
    "    \"\"\" \n",
    "    Plot how much each column of our data contributes \n",
    "    to each principal component and labels the rows of V^T.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'v':vt[k, :], 'Column names':col_names})\n",
    "    chart = alt.Chart(df).mark_bar().encode(\n",
    "        x='Column names',\n",
    "        y='v',\n",
    "        opacity=alt.value(0.7)\n",
    "    ).configure_axis(\n",
    "        labelFontSize=12,\n",
    "        titleFontSize=14\n",
    "    ).configure_axisX(\n",
    "        labelAngle = 0\n",
    "    ).properties(width = 400)\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If you get a ValueError: arrays must all be same length\n",
    "### Go back to question 2e and read the note about NOT overwriting\n",
    "### `u, s, vt` that you defined earlier.\n",
    "\n",
    "plot_pc(list(df_1972_to_2016_num.columns), vt1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, plot the the 2nd row of $V^T$. \n",
    "\n",
    "*Hint:* You are just copying and pasting code from the cell above and then changing one number.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2h\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2i\n",
    "\n",
    "**Using your plots from Question 2h as well as the original table**, give a description of what it means to have a relatively large positive value for `pc1` (right side of the 2D scatter plot), and what it means to have a relatively large positive value for `pc2` (top side of the 2D scatter plot).\n",
    "\n",
    "In other words, what is generally true about a state with relatively large positive value for `pc1`? For a large positive value for `pc2`?\n",
    "\n",
    "Note: `pc2` is pretty hard to interpret, and we don't really have a concensus on what it means either. We'll be nice when grading: we just want to see your best attempt at an explanation.\n",
    "\n",
    "Note: Principal components beyond the first are often hard to interpret (but not always, see question 1 earlier in this homework).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2i\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this cell for scratch work. \n",
    "# If you need more scratch space, add cells *below* this one.\n",
    "\n",
    "# Make sure to put your actual answer in the cell ABOVE, next to the word SOLUTION: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2j\n",
    "\n",
    "To get a better sense of whether our 2D scatterplot captures the whole story, create a scree plot for this data. On the y-axis plot the fraction of the total variance captured by the ith principal component. You should see that the first two principal components capture quite a bit of the variance. It is partially for this reason that the 2D scatter plot was so much more useful for this dataset.\n",
    "\n",
    "*Hint:* Your code will be very similar to the scree plot from problem 1d. Be sure to label your axes appropriately!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2j\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw your Altair visualization\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are finished with this homework on Principal Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Running Built-in Tests\n",
    "1. All tests are in `tests` directory\n",
    "1. Each python file in `tests` is a test\n",
    "1. `grader.check('testname')` runs test `'testname'`, e.g. `'q1'`\n",
    "1. `grader.check_all()` runs all visible tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Run built-in checks\n",
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pdf in classic notebook (does not work in JupyterLab)\n",
    "import nb2pdf\n",
    "nb2pdf.convert('hw4.ipynb')\n",
    "\n",
    "# To generate pdf using command-line, run in terminal,\n",
    "# nb2pdf hw4.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submission Checklist\n",
    "1. Check filename is 'hw4.ipynb'\n",
    "1. Save file to confirm all changes are on disk\n",
    "1. Run *Kernel > Restart & Run All* to execute all code from top to bottom\n",
    "1. Check `grader.check_all()` output\n",
    "1. Save file again to write any new output to disk\n",
    "1. Check generated pdf that all responses are displayed correctly\n",
    "1. Submit to Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
