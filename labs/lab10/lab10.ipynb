{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.469577Z",
     "start_time": "2018-04-02T16:07:15.663122Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install plotly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification and Logistic Regression\n",
    "\n",
    "This lab is more of a walkthrough than a coding exercise. All questions in this lab are free response, so turn in a pdf to Gradescope.\n",
    "\n",
    "The goal of this lab is to give you ideas on how to classify data into 2 categories, with a little extra note on how to predict more categories.\n",
    "\n",
    "This assignment should be completed and submitted before **11:59 PM on Friday, June 5, 2020**.\n",
    "\n",
    "Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk to others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the following cell:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For this lab we will use the Pokemon Gen VI Tierlist Dataset which we can obtain from [kaggle](https://www.kaggle.com/notgibs/smogon-6v6-pokemon-tiers). You can find the description of the original attributes [here](https://www.kaggle.com/abcsds/pokemon).\n",
    "\n",
    "- **X.**: Pokedex Number\n",
    "- **Name**: Name of each pokemon\n",
    "- **Type 1**: Primary type. Each pokemon has a type, this determines weakness/resistance to attacks.\n",
    "- **Type 2**: Secondary type. Some pokemon are dual type and have two types.\n",
    "- **Total**: sum of all stats given below, a general guide to how strong a pokemon is.\n",
    "- **HP**: hit points, or health, defines how much damage a pokemon can withstand before fainting.\n",
    "- **Attack**: the base modifier for normal attacks (e.g., Scratch, Punch).\n",
    "- **Defense**: the base damage resistance against normal attacks.\n",
    "- **SP Atk**: special attack, the base modifier for special attacks (e.g., fire blast, bubble beam).\n",
    "- **SP Def**: the base damage resistance against special attacks.\n",
    "- **Speed**: determines which pokemon attacks first each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.590723Z",
     "start_time": "2018-04-02T16:07:17.472304Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pokemon.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.599437Z",
     "start_time": "2018-04-02T16:07:17.593220Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Tier\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokemon in the competitive scene can be classified into several tier lists and can be played in any format that they are listed in and above. In today's lab, we will consider a pokemon to be competitively viable (called \"being in meta\") if they are in tier UU or above, meaning that the following tiers will be considered \"meta.\" (*If you are curious, you can read more about the [explanation of tiers](https://pokemon.neoseeker.com/wiki/Tier_listings)*).\n",
    "\n",
    "* AG\n",
    "* Uber\n",
    "* OU\n",
    "* BL\n",
    "* UU\n",
    "* BL2\n",
    "\n",
    "\n",
    "Create a new column `\"Meta\"` that is True when a pokemon is not in the above tiers, and False when a pokemon is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Meta\"] = df[\"Tier\"].isin([\"AG\", \"Uber\", \"OU\", \"BL\", \"UU\", \"BL2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "sum(df[\"Meta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize and classify our pokemon's we will use the `Total` column (i.e., a sum of all stats, which explains the overall pokemon's strength).\n",
    "\n",
    "Altair allows us to automatically nicely visualize the spread of the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_tick().encode(\n",
    "    x = 'Total', \n",
    "    y = 'Meta',\n",
    "    color = 'Meta'\n",
    ").configure_axis(\n",
    "    labelFontSize=14, # change axes label font size\n",
    "    titleFontSize=16  # change axes title font size\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=200\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a better way to visualize the data is using stacked histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the options common to all layers\n",
    "brush = alt.selection(type='interval')\n",
    "base = alt.Chart(df).add_selection(brush)\n",
    "\n",
    "hist = alt.Chart(df).transform_fold(\n",
    "    ['Meta', 'Total']\n",
    ").mark_area(\n",
    "    opacity=0.5,\n",
    "    interpolate='step'\n",
    ").encode(\n",
    "    alt.X('Total:Q', bin=alt.Bin(maxbins=30)),\n",
    "    alt.Y('count()', stack=None),\n",
    "    alt.Color('Meta')\n",
    "    #color = alt.condition(brush, 'malignant', alt.value('grey'))\n",
    ")\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to visualize these data as a scatterplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point().encode(\n",
    "    x = 'Total:Q', \n",
    "    y = 'Meta:Q',\n",
    "    color = 'Meta'\n",
    ").configure_axis(\n",
    "    labelFontSize=14, # change axes label font size\n",
    "    titleFontSize=16  # change axes title font size\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Regression\n",
    "\n",
    "\n",
    "**Goal:** We would like to predict whether a Pokemon is meta or not based on the sum of its stat values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define $X$ and $Y$ as variables containing the training features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.931358Z",
     "start_time": "2018-04-02T16:07:17.926492Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[['Total']].values\n",
    "Y = df['Meta'].values.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a least squares regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.006048Z",
     "start_time": "2018-04-02T16:07:17.933377Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "least_squares_model = linear_model.LinearRegression()\n",
    "least_squares_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is our fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding small amount of noise avoids overplotting when we draw our scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_y = Y + 0.1*np.random.rand(len(Y)) - 0.05\n",
    "jitter_x = X + 10*np.random.rand(len(X), 1) - 5\n",
    "print(jitter_x.shape)\n",
    "points = go.Scatter(name=\"Jittered Data\", \n",
    "                    x=np.squeeze(jitter_x), y = jitter_y, \n",
    "                    mode=\"markers\", marker=dict(opacity=0.5))\n",
    "X_plt = np.linspace(np.min(X), np.max(X), 10)\n",
    "model_line = go.Scatter(name=\"Least Squares\",\n",
    "    x=X_plt, y=least_squares_model.predict(X_plt[:,np.newaxis]), \n",
    "    mode=\"lines\", line=dict(color=\"orange\"))\n",
    "py.iplot([points, model_line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Root Mean Squared Error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.032417Z",
     "start_time": "2018-04-02T16:07:18.028104Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "print(\"RMSE:\", np.sqrt(mse(Y, least_squares_model.predict(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "1. Are we happy with the fit?\n",
    "2. What is the meaning of predictions that are neither 0 or 1?\n",
    "3. Put the RMSE in context of the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Error\n",
    "\n",
    "This is a classification problem so we probably want to measure how often we predict the correct value.  This is sometimes called the zero-one loss (or error):\n",
    "\n",
    "$$ \\large\n",
    "\\textbf{ZeroOneLoss} = \\frac{1}{n} \\sum_{i=1}^n \\textbf{I}\\left[ y_i \\neq f_\\theta(x) \\right]\n",
    "$$\n",
    "\n",
    "However to use the classification error we need to define a decision rule that maps $f_\\theta(x)$ to the $\\{0,1\\}$ classification values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Decision Rule\n",
    "\n",
    "Suppose we instituted the following simple decision rule:\n",
    "\n",
    "$$\\Large\n",
    "\\text{If } f_\\theta(x) > 0.5  \\text{ predict 1 (meta) else predict 0 (non-meta).}\n",
    "$$\n",
    "\n",
    "This simple **decision rule** is deciding that a Pokemon is meta if our model predicts a values above 0.5 (closer to 1 than zero).\n",
    "\n",
    "In the following we plot the implication of these decisions on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.059302Z",
     "start_time": "2018-04-02T16:07:18.034361Z"
    }
   },
   "outputs": [],
   "source": [
    "jitter_y = Y + 0.1*np.random.rand(len(Y)) - 0.05\n",
    "jitter_x = X + 10*np.random.rand(len(X), 1) - 5\n",
    "ind_mal = least_squares_model.predict(X) > 0.5\n",
    "\n",
    "mal_points = go.Scatter(name=\"Classified as meta\", \n",
    "                    x=np.squeeze(jitter_x[ind_mal]), y = jitter_y[ind_mal], \n",
    "                    mode=\"markers\", marker=dict(opacity=0.5, color=\"red\"))\n",
    "ben_points = go.Scatter(name=\"Classified as non-meta\", \n",
    "                    x=np.squeeze(jitter_x[~ind_mal]), y = jitter_y[~ind_mal], \n",
    "                    mode=\"markers\", marker=dict(opacity=0.5, color=\"blue\"))\n",
    "dec_boundary = (0.5 - least_squares_model.intercept_)/least_squares_model.coef_[0]\n",
    "dec_line = go.Scatter(name=\"Least Squares Decision Boundary\", \n",
    "                      x = [dec_boundary,dec_boundary], y=[-0.5,1.5], mode=\"lines\",\n",
    "                     line=dict(color=\"black\", dash=\"dot\"))\n",
    "py.iplot([mal_points, ben_points, model_line,dec_line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `ZeroOneLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.067202Z",
     "start_time": "2018-04-02T16:07:18.061723Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "print(\"Training Fraction incorrect:\", \n",
    "      zero_one_loss(Y, least_squares_model.predict(X) > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "1. Are we happy with this error level?\n",
    "1. 40% of eligible pokemon are considered meta. If we only guessed the majority label (meta, non-meta), what percent would we get wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Can we think of the line as a \"probability\"?\n",
    "\n",
    "\n",
    "Not really.  Probabilities are constrained between 0 and 1.   How could we learn a model that captures this probabilistic interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Could we just truncate the line?\n",
    "\n",
    "Maybe we can define the probability as:\n",
    "\n",
    "$$ \\large\n",
    "p_i = \\min\\left(\\max \\left( x^T \\theta , 0 \\right), 1\\right)\n",
    "$$\n",
    "\n",
    "this would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.131948Z",
     "start_time": "2018-04-02T16:07:18.128385Z"
    }
   },
   "outputs": [],
   "source": [
    "def bound01(z):\n",
    "    u = np.where(z > 1, 1, z)\n",
    "    return np.where(u < 0, 0, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.155130Z",
     "start_time": "2018-04-02T16:07:18.134002Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plt = np.linspace(np.min(X), np.max(X), 100)\n",
    "p_line = go.Scatter(name=\"Truncated Least Squares\",\n",
    "    x=X_plt, y=bound01(least_squares_model.predict(np.array([X_plt]).T)), \n",
    "    mode=\"lines\", line=dict(color=\"green\", width=8))\n",
    "py.iplot([mal_points, ben_points, model_line, p_line, dec_line], filename=\"lr-06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far least squares regression seems pretty reasonable and we can \"force\" the predicted values to be bounded between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "In most cases, a truncated linear regression is not a robust enough model to predict probabilities because it is very sensitive to outliers. This is why in most cases, we use logistic regression to model probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(solver='lbfgs').fit(X,Y)\n",
    "Y_pred = logistic_model.predict(np.linspace(200,800,100).reshape(-1,1))\n",
    "source1 = pd.DataFrame({\n",
    "    'x': X.squeeze(),\n",
    "    'y': Y\n",
    "})\n",
    "source2 = pd.DataFrame({\n",
    "    'model_x': np.linspace(200,800,100),\n",
    "    'model_y': Y_pred\n",
    "})\n",
    "alt.Chart(source1).mark_point().encode(\n",
    "    x='x',\n",
    "    y='y'\n",
    ") + alt.Chart(source2).mark_line(color=\"red\").encode(\n",
    "    x=alt.X('model_x', title=\"Total stat values\", scale= alt.Scale(zero=False)),\n",
    "    y=alt.Y('model_y', title=\"Probability of being meta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the logistic regression line looks similar to our decision boundary that we chose earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also expect the accuracy to be around the same as our decision boundary in this case. Let's also take a look at our RMSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraction incorrect:\", \n",
    "      zero_one_loss(Y, logistic_model.predict(X) > 0.5))\n",
    "print(\"RMSE:\", \n",
    "      np.sqrt(mse(Y, logistic_model.predict(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Notice how the RMSE is larger for logistic regression. Why do you think this is, and is this kind of loss useful for this kind of model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification (Generalized Logistic Regression)\n",
    "\n",
    "The rest of this notebook is just informational. There are no further questions, but you may find this useful for your final project.\n",
    "\n",
    "Logistic regression can be thought of as binary classification, where we pick between the 0 class and the 1 class. In many cases, there are not just two classes we would like to predict. For this Pokemon dataset, we would instead like to predict the highest format that a Pokemon with a certain set of stats will be legal under. \n",
    "\n",
    "First let's edit our dataframe so that it's easier to use and designate indexes to categories and combines the respective banlists and tiers (so the class is the format rather than the tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_classification = df[[\"HP\", \"Attack\", \"Defense\", \"Sp..Atk\", \"Sp..Def\", \"Legendary\", \"Mega\"]]\n",
    "df_classification = df_classification.astype(\"int64\")\n",
    "df_target = df[\"Tier\"].replace({\"AG\":0,\n",
    "                                \"Uber\":1,\n",
    "                                \"OU\":2,\n",
    "                                \"BL\":2,\n",
    "                                \"UU\":3, \n",
    "                                'BL2':3, \n",
    "                                'RU':4, \n",
    "                                'BL3':4, \n",
    "                                'NU':5, \n",
    "                                'BL4':5,\n",
    "                                'PU':6})\n",
    "target_onehot = pd.get_dummies(df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check how many examples of each tier we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tier'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 7 different categories that we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get probabilities of each category, we will use a special kind of function called the softmax function that takes an array of weights and turns them into probabilities according to this function:\n",
    "\n",
    "$$\\large p_i = \\frac{exp(x_i)}{\\sum_{j}^{ }exp(x_j))}$$\n",
    "Let's define a loss function that can handle multiple classes. This is called cross entropy, and one of its additional properties is it is robust to class imbalances.\n",
    "\n",
    "$$\\large-\\sum_{c=1}^My_{o,c}\\log(p_{o,c})$$\n",
    "\n",
    "Where $M$ is the number of classes, $y$ is a binary indicator for whether the observed class is correct, and $p$ is the probability that the observation is of class $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def cross_entropy(prediction, target, epsilon=1e-12):\n",
    "    predictions = np.clip(prediction, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(np.sum(target*np.log(predictions+1e-9)))\n",
    "    return ce\n",
    "\n",
    "def softmax_cross_entropy(weights):\n",
    "    weights = weights.reshape(7,7)\n",
    "    p = softmax(df_classification @ weights, axis=1)\n",
    "    return cross_entropy(p, target_onehot)\n",
    "    \n",
    "softmax_cross_entropy(np.zeros((7,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to minimize this loss function using scipy's library. Normally we would want to use something like gradient descent, but to keep the code simple, we will use this prebuilt function. This can take a while, so sit back and relax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "m = minimize(softmax_cross_entropy, x0=np.zeros((7,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, what we created here is mostly known as a **Perceptron**, and it is the basic building block of many neural networks. Let's see how well it did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def predict(df, weights):\n",
    "    return (df_classification @ weights.reshape(7,7)).idxmax(axis=1)\n",
    "\n",
    "y_pred = predict(df_classification, m['x'])\n",
    "\n",
    "color = confusion_matrix(df_target,y_pred, normalize='true')\n",
    "x,y = np.meshgrid(range(0,7),range(0,7))\n",
    "source = pd.DataFrame({\n",
    "    'x':x.ravel(),\n",
    "    'y':y.ravel(),\n",
    "    'z':color.ravel()\n",
    "})\n",
    "alt.Chart(source).mark_rect().encode(\n",
    "    x=alt.X('x:O', title=\"Predicted\"),\n",
    "    y=alt.Y('y:O', title=\"Target\"),\n",
    "    color='z:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a confusion matrix, and it tells us what proportion of each class our model predicted vs what the actual class is. Ideally, we would have a dark diagonal, but we can see that our model predicts a lot of Pokemon to be in the PU format. This is probably due to a various number of reasons. Most likely, there are more pokemon in the PU format, and their stats closely resemble those found in UU, RU, and NN, so we need to look at more data than just the numerical values of the pokemon like the types, movesets, and abilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save as a pdf, click `File` -> `Download as` -> `PDF`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
