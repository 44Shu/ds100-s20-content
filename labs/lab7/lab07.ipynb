{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# initializing otter-grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Simple Linear Regression\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this lab, we'll review some of the details of how linear regression works. \n",
    "\n",
    "We will also show how to do linear regression using various real world tools including Altair's `transform_regression`, `scipy.optimize`, and `scikit-learn`. In real world data science work, you are far more likely to use something similar to the former (`transform_regression`) and latter (`scikit-learn`) approaches, but it's important to know how to use the formulaic and the `scipy.optimize` approaches so that you understand what's really going on.\n",
    "\n",
    "**This assignment should be completed and submitted before 11:59 PM on Friday, May 15, 2020.**\n",
    "\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk to others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_List collaborators here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the tips dataset from seaborn's dataset bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we're interested in studying the **relationship between two variables**. Specifically, we're interested in the relationship between the `total_bill` column and `tip` column. Our goal will be to predict tips ($Y$) from total_bill ($x$). In other words, we want to find values of $\\alpha$ and $\\beta$ so that given the value of $x$, we can predict $Y$\n",
    "$$\\boxed{Y = \\alpha + \\beta x}$$\n",
    "We will now explore different ways to obtain the optimal values of $\\alpha, \\beta$, called $\\hat{\\alpha}, \\hat{\\beta}$, where $\\hat{Y} = \\hat{\\alpha} + \\hat{\\beta}x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build a boilerplate regression plot in altair, which will both provide a scatterplot of `tip` vs `total_bill` and also display the least-squares line of best fit. This method of creating a regression line is great for quickly calculating the regression line when doing data analysis; however, in this lab, we will look a bit deeper into this line. This line of best fit is what we will look to determine empirically in three different ways: manually using the formula from lecture, `scipy.optimize`, and `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(tips).mark_point().encode(\n",
    "    x='total_bill',\n",
    "    y='tip'    \n",
    ")\n",
    "chart + chart.transform_regression('total_bill', 'tip').mark_line(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 – Manual Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the following expression for the line of best fit.\n",
    "\n",
    "$$\\hat{y_i} = \\bar{y} + r \\frac{SD(y)}{SD(x)} (x_i - \\bar{x})$$\n",
    "\n",
    "where $\\bar{x}$, $\\bar{y}$, $SD(x)$, $SD(y)$ correspond to the means and standard deviations of $x$ and $y$, respectively, and $r$ is the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1a\n",
    "\n",
    "Assign `xbar`, `ybar`, `stdx`, `stdy`, and `r`, such that they align with our dataset.\n",
    "\n",
    "- Hint: Remember, in our case, `y` is `tip`, and `x` is `total_bill`.\n",
    "- Hint: Use `np.corrcoef` to compute `r`. Note that the output of `np.corrcoef` is a **matrix, not a number**, so you'll need to collect the correlation coefficient by **indexing into the returned array**. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 5\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar = ...\n",
    "ybar = ...\n",
    "stdx = ...\n",
    "stdy = ...\n",
    "r = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, set `b_hat` and `a_hat` correctly, in terms of the variables you defined above. Remember that `b_hat` and `a_hat` are our regression line's intercept and slope, respectively.\n",
    "\n",
    "- Hint: Try and match the slope and intercept in $\\hat{y_i} = \\hat{\\alpha} + \\hat{\\beta}x_i$ to the slope and intercept in $\\hat{y_i} = \\bar{y} + r \\frac{SD(y)}{SD(x)} (x_i - \\bar{x})$.\n",
    "\n",
    "- Hint: You may want to define `a_hat` in terms of `b_hat` (i.e., solve for `b_hat` and then use it to find `a_hat`).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat = ...\n",
    "a_hat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "Now, use `a_hat` and `b_hat` to predict the tip for a total bill amount of \\$20. Store your result in `predicted_20`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_20 = ...\n",
    "predicted_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1d\n",
    "Define `regression` as a `pd.Series` containg predicted values of $Y$ values (i.e., predicted `\"tip\"` values) for the observed values of total bills (`tips[\"total_bill\"]`). You will need to use `a_hat`, `b_hat`, and `tips[\"total_bill\"]`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1e\n",
    "\n",
    "Now, create the scatter plot of `tip` vs `total_bill`, along with the regression line you just calculated on the same plot.\n",
    "\n",
    "* **Hint:** You'll need to create a new dataframe to plot the regression line \n",
    "* **Hint:** You will want the y axis to be the regression values you calculated in the last part\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1e\n",
    "points: 4\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $r$, the correlation coefficient between `tips` and `total_bill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "**In the cell below**, comment on the value of $r$, and what it means in the context of the above scatter plot.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1f\n",
    "points: 3\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 – Using Scipy Minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.minimize` is a powerful method that can determine the optimal value of a variety of different functions. In practice, it is used to minimize functions that have no (or difficult to obtain) analytical solutions (it is a **numerical method**).\n",
    "\n",
    "It is overkill for our simple example, but nonetheless, we will show you how to use it, as it will become useful in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "Firstly, fill out the definition of `L2_tip_loss` so that it computes the empirical risk for a given choice of $\\alpha$ and $\\beta$. That is, it computes\n",
    "\n",
    "$$\\frac{1}{n} \\sum_{i = 1}^n(y_i - (\\alpha + \\beta x_i))^2$$\n",
    "\n",
    "where, again, $x$ and $y$ refer to `\"total_bill\"` and `\"tip\"`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_tip_loss(a, b):\n",
    "    \"\"\"Returns average L2 loss between regression line for \n",
    "       intercept a and slope b\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out different `a` and `b` values. Observe that if you pick values close to `a_hat` and `b_hat` then the loss is lower. \n",
    "\n",
    "In fact, in linear regression, we are trying to minimize the sum of squares error when picking the slope `a_hat` and intercept `b_hat` of the regression line. We are able to calculate it directly using the formulas in question 1, but had our model required the minimization of a function that had no analytical solution, we would be using this function to approximate the values needed to minimize our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_tip_loss(0.9, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minimize` function we saw in Lab 2 can also minimize functions of multiple variables. There's one quirk, however, which is that the function has to **accept its parameters as a single list**.\n",
    "\n",
    "For example, consider the multivariate $f(u, v) = u^2 - 2 u v - 3 v + 2 v^2$. It turns out this function's minimum is at $(1.5, 1.5)$. To minimize this function, we create `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta):\n",
    "    u = theta[0]\n",
    "    v = theta[1]\n",
    "    return u**2 - 2 * u * v - 3 * v + 2 * v**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "minimize(f, x0 = [0.0, 0.0]) \n",
    "\n",
    "# As an aside: x0 is the \"initial guess\" for the optimal theta. minimize works iteratively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Define `L2_tip_loss_list` which is exactly like `L2_tip_loss` except that it takes in **a single list of 2 variables** rather than two separate variables. For example `L2_tip_loss_list([2, 3])` should return the same value as `L2_tip_loss(2, 3)`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_tip_loss_list(theta):\n",
    "    \"\"\"Returns average L2 loss between regression line for \n",
    "       intercept a and slope b\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2c\n",
    "\n",
    "Now, set `minimized` to the result of calling `minimize` to optimize this loss function.\n",
    "\n",
    "- Hint: Make sure to set `x0`. (Try using the origin.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "points: 2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimized = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output of your call to `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will print out the values of `a_hat` and `b_hat` computed from both methods (\"manual\" refers to the technique in Question 1). If you've done everything correctly, these should be very close to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a_hat_scipy: ', minimized['x'][0])\n",
    "print('a_hat_manual: ', a_hat)\n",
    "print('\\n')\n",
    "print('b_hat_scipy: ', minimized['x'][1])\n",
    "print('b_hat_manual: ', b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason these don't match past the first 5 decimal places is due to the fact that `scipy.minimize` is a numerical method, meaning it approximates the optimal value using some sort of non-algebraic procedure. For our purposes, though, these values are essentially the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 – Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another way to fit a linear regression model is to use scikit learn, an industry standard package for machine learning applications. \n",
    "\n",
    "To do so, we first create a `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `model` is like a \"blank slate\" for a linear model. Now, we need to tell `model` to \"fit\" itself to the data. Essentially, this is doing exactly what you did in the previous part of this lab (creating a loss function and finding the parameters that minimize that loss).\n",
    "\n",
    "<i>Note: `X` needs to be a matrix (or DataFrame), as opposed to a single array (or Series). This is because `sklearn.linear_model` is robust enough to be used for multiple regression.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X = tips[['total_bill']], y= tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model exists, we can look at the `a_hat` and `b_hat` values it found, which are given in the attributes `intercept` and `coef`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat_sklearn = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat_sklearn = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a_hat_scipy: ', minimized['x'][0])\n",
    "print('a_hat_manual: ', a_hat)\n",
    "print('\\n')\n",
    "print('b_hat_scipy: ', minimized['x'][1])\n",
    "print('b_hat_manual: ', b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the `scikit-learn` linear regression model to make predictions, you can use the `model.predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array(20).reshape(-1,1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line of code tells us that `model` predicts a tip of \\$3.02 given a total bill amount of 20 dollars. This is the same as doing `a_hat + b_hat * 20` as in Question 1c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "Create a linear regression plot using `model.predict`. It should look very similar (if not the same) as your plot from Question 1d.\n",
    "\n",
    "* **Hint**: Use `np.linspace()` to create your x-axis\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 5\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Graduate Admissions\n",
    "\n",
    "We will now explore a dataset concerning the acceptance rates of graduate students. This data is taken from [Kaggle](https://www.kaggle.com/mohansacharya/graduate-admissions) and sourced from a paper presented at the IEEE International Conference on Computation Intelligence in Data Science in 2019.\n",
    "\n",
    "Using `pd.read_csv()`, load the dataset `\"admissions.csv\"`. Then calculate the regression line of `GRE Score` to `Chance of Admit` using any of the methods discussed in this lab. Then display a plot showing the data and the regression line that you calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATE YOUR REGRESSION LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT YOUR REGRESSION LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b - Communicate Your Results\n",
    "\n",
    "Explain in the cell below the significance of your regression line (Write down your analysis of it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 BONUS\n",
    "\n",
    "Answer all the questions in the cell below to get bonus points\n",
    "* Why is linear regression not the best estimate for the admissions chance variable that we see in this dataset, and specifically where does our regression line break down?\n",
    "* What is another regression model that would more accurately fit the domain of values seen in the `Chance of Admit` column? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congrats!** You are finished with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Running Built-in Tests\n",
    "1. All tests are in `tests` directory\n",
    "1. Each python file in `tests` is a test\n",
    "1. `grader.check('testname')` runs test `'testname'`, e.g. `'q1'`\n",
    "1. `grader.check_all()` runs all visible tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Run built-in checks\n",
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pdf in classic notebook (does not work in JupyterLab)\n",
    "import nb2pdf\n",
    "nb2pdf.convert('lab07.ipynb')\n",
    "\n",
    "# To generate pdf using command-line, run in terminal,\n",
    "# nb2pdf lab07.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submission Checklist\n",
    "1. Check filename is 'lab07.ipynb'\n",
    "1. Save file to confirm all changes are on disk\n",
    "1. Run *Kernel > Restart & Run All* to execute all code from top to bottom\n",
    "1. Check `grader.check_all()` output\n",
    "1. Save file again to write any new output to disk\n",
    "1. Check generated pdf that all responses are displayed correctly\n",
    "1. Submit to Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
