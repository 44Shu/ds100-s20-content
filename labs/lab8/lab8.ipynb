{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# initializing otter-grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Multiple Linear Regression\n",
    "\n",
    "In this lab, you will be working with the diamond dataset. You will fit a linear model to predict the price of a diamond using its characteristics. You will get experience with extracting and creating features  using techniques such as one-hot encoding or log transformation to improve the accuracy of your model. At the end, you will get a chance to create your own features for the linear model! \n",
    "\n",
    "**This lab should be completed and submitted by 11:59 PM on Friday May 22, 2020.**\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually** and do not copy them from others. \n",
    "\n",
    "By submitting your work in this course, whether it is homework, a lab assignment, or a quiz/exam, you agree and acknowledge that **this submission is your own work and that you have read the policies regarding Academic Integrity**: https://studentconduct.sa.ucsb.edu/academic-integrity. The Office of Student Conduct has policies, tips, and resources for proper citation use, recognizing actions considered to be cheating or other forms of academic theft, and studentsâ€™ responsibilities. You are required to read the policies and to abide by them.\n",
    "\n",
    "*List collaborators here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary\n",
    "\n",
    "First, we load the diamond dataset and look at the fields in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diamonds.csv.zip\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each record in the dataset corresponds to a single diamond.  The fields are\n",
    "\n",
    "1. **carat**: The weight of the diamonds.\n",
    "2. **cut**: The quality of the cut. This is an *ordinal* variable which takes on a value in the set: {`Fair`, `Good`, `Very Good`, `Premium`, and `Ideal`}.\n",
    "3. **color**: The color of the diamond. This is an *ordinal* variable which takes on a value from the set of characters between `J` (worst) and `D` (best).\n",
    "4. **clarity**: How obvious inclusions are within the diamond. This is an *ordinal* variable that takes on a value from the set: {`I1` (worst), `SI2`, `SI1`, `VS2`, `VS1`, `VVS2`, `VVS1`, `IF` (best)}.\n",
    "5. **depth**: The height of a diamond, measured from the culet to the table, divided by its average girdle diameter.\n",
    "6. **table**: The width of the diamond's table expressed as a percentage of its average diameter.\n",
    "7. **price**: Price of the diamond in USD.\n",
    "8. **x**: Length of the diamond measured in mm.\n",
    "9. **y**: Width of the diamond measured in mm.\n",
    "10. **z**: Depth of the diamond measured in mm.\n",
    "\n",
    "We are interested in **predicting the price of a diamond given it's characteristics**.  Mathematically, we would like to fit a linear model with parameters $\\theta$ corresponding to features $\\textbf{x}$ to best capture the price of the diamonds:\n",
    "\n",
    "$$\n",
    "f_{\\theta} (\\textbf{x}) \\rightarrow \\text{Price}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "For the first part of the lab, we will be focusing on diamond's **carat**, **depth**, and **table** characteristics. Hence $\\textbf{x} = [$ **carat**, **depth**, **table** $]$ for a given diamond.\n",
    "\n",
    "We are interested in using a linear model with a bias term as our model. We could express the model mathematically as:\n",
    "\n",
    "$$\n",
    "f_\\theta(\\textbf{x}) = f_\\theta\\left(\\textbf{carat}, \\textbf{depth}, \\textbf{table}\\right)\n",
    "=\n",
    "\\theta_0 + \n",
    "\\theta_1 * \\textbf{carat} +\n",
    "\\theta_2 * \\textbf{depth} +\n",
    "\\theta_3 * \\textbf{table}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1a\n",
    "Set the variable `data1` to be a subset of the original dataframe `data` such that `data1` only contains the columns `carat`, `depth`, `table` and `price`. (Note that the order of the columns in dataframe `data1` should follow the order `carat`, `depth`, `table`, `price` in order to pass the autograder test.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: false\n",
    "points: 3\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we split `data1` into two variables:\n",
    "\n",
    "(1) Target values `y`: this consists of the prices of the diamonds.\n",
    "\n",
    "(2) Set of features `X_features`: this is a data frame where each row is a feacture vector consisting of features $[$ **carat**, **depth**, **table** $]$ (without the bias term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data1['price']\n",
    "X_features = data1[['carat', 'depth', 'table']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b \n",
    "We defined a function `add_bias` which takes in a dataframe and adds a column of 1's to the left of the input dataframe. This function should modify the input dataframe in place. Please fill in this function with your solution. **Please name this extra column 'ones' in the dataframe.** After calling the function on `X_features` you will get a dataframe whose first five rows of `X_features` will look like the following:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>ones</th>\n",
    "      <th>carat</th>\n",
    "      <th>depth</th>\n",
    "      <th>table</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>1.0</td>\n",
    "      <td>0.23</td>\n",
    "      <td>61.5</td>\n",
    "      <td>55.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>1.0</td>\n",
    "      <td>0.21</td>\n",
    "      <td>59.8</td>\n",
    "      <td>61.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>1.0</td>\n",
    "      <td>0.23</td>\n",
    "      <td>56.9</td>\n",
    "      <td>65.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>1.0</td>\n",
    "      <td>0.29</td>\n",
    "      <td>62.4</td>\n",
    "      <td>58.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>1.0</td>\n",
    "      <td>0.31</td>\n",
    "      <td>63.3</td>\n",
    "      <td>58.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Hint: You might find `pd.insert` method to be useful as you can specify the column index for the newly-added column: https://www.geeksforgeeks.org/python-pandas-dataframe-insert/**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "manual: false\n",
    "points: 5\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(data):\n",
    "...\n",
    "    \n",
    "X = X_features.copy() \n",
    "add_bias(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c ###\n",
    "We need a loss function to evaluate how good our model approximates the prices of the diamonds. In the cell below, complete the function `avg_squared_loss` which returns the average squared loss between true target values `y` and our predictions `y_hat`. Note that both inputs, `y` and `y_hat`, to the function are arrays. You can assume that they have the same length. \n",
    "\n",
    "Recall that the average squared loss is defined as:\n",
    "$$\n",
    "Avg\\ Squared\\ Loss(y, \\hat{y}) = \\frac{1}{n} \\sum\\limits_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "manual: false\n",
    "points: 3\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_squared_loss(y, y_hat):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build our linear model. We saw that the **predictions** for the entire data set, $\\hat{\\mathbb{Y}}$, with a linear model can be computed as:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbb{Y}} = \\mathbb{X} \\theta  \n",
    "$$\n",
    "\n",
    "The **covariate matrix** $\\mathbb{X} \\in \\mathbb{R}^{n \\times (d+1)}$ consists of $n$ rows where each row corresponds to a record in the dataset and the $d+1$ columns correspond to the $d$ features extracted from the data plus an additional bias term.\n",
    "\n",
    "The following function `linear_model` computes the prediction $\\hat{\\mathbb{Y}}$ given parameters $\\theta$ and covariate matrix $\\mathbb{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(theta, X): \n",
    "    return X @ theta # The @ symbol is matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the `@` symbol is the matrix multiply operation and is equivalent to writing `X.dot(theta)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1d\n",
    "In the cell below, choose any `theta` you would like (please note that the dimension of the `theta` you choose should match the number of columns of the covariate matrix) and make predictions for `Y` using the linear model defined above given the `theta` you chose. Assign the variable `Y_hat` with the predictions and the variable `loss` with the average squared loss of your predictions based on the `theta` you chose.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "manual: false\n",
    "points: 3\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice the loss of the predictions for an arbitrary choice of `theta` is quite big. We can find the optimal `theta` by minimizing the mean square loss:\n",
    "\n",
    "\\begin{align}\n",
    "L(\\theta) &= \\frac{1}{n}\\sum_{i=1}^n \\left( \\mathbb{Y}_i - \\left(\\mathbb{X} \\theta\\right)_i \\right)^2 \\\\\n",
    "&= \\frac{1}{n}\\sum_{i=1}^n \\left( \\mathbb{Y}_i - \\mathbb{X}_i \\theta \\right)^2 \\\\\n",
    "&= \\frac{1}{n} || \\mathbb{Y} - \\mathbb{X} \\theta ||_2^2 \\\\\n",
    "&= \\frac{1}{n}\\left( \\mathbb{Y} - \\mathbb{X}\\theta \\right)^T \\left( \\mathbb{Y} - \\mathbb{X}\\theta \\right)\n",
    "\\end{align}\n",
    "\n",
    "By taking derivative with respect to $\\theta$ and set the derivative equal to 0. We can get the normal equation: \n",
    "\n",
    "$$\n",
    "(\\mathbb{X}^T \\mathbb{X}) \\hat{\\theta} = \\mathbb{X}^T \\mathbb{Y}\n",
    "$$\n",
    "\n",
    "Solving for $\\hat{\\theta}$ in the above equation gives us the minimizer of the squared loss with respect to our data.  \n",
    "\n",
    "If $\\mathbb{X}^T \\mathbb{X}$ is invertible (full rank), $\\hat{\\theta}$ can be computed analytically as:\n",
    "\n",
    "$$\n",
    " \\hat{\\theta} = \\left( \\mathbb{X}^T \\mathbb{X} \\right)^{-1} \\mathbb{X}^T \\mathbb{Y}.\n",
    "$$\n",
    "\n",
    "We will not use the above analytic approach for solving $\\hat{\\theta}$ in this lab. Instead, we will use the `sklearn` library to fit our model and find the optimal $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearRegression model from sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1e\n",
    "In lab7 we have learned how to use the sklearn package to create a linear regression model, as well as using it to fit on the data and get the predicted values. Today we are going to use it again. In case you are not familiar with the syntax, check lab7 to get refreshed! In the cell below, \n",
    "1. Fit a linear model `model1` using `X` and `Y` defined earlier in the lab. \n",
    "2. Make predictions `Y_hat1` for `Y` using the fitted model.\n",
    "3. Calculate the average squared loss `loss1` of your prediction.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1e\n",
    "manual: false\n",
    "points: 6\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we create a scatter plot by plotting (`Y`, `Y_hat1`). The red line is the identity line where each point on the line has the same values for the variables representing the x-axis and y-axis. If our model is very accurate, we would expect $Y \\approx Y_{hat1}$, and thus all the points should be very close to the identity line. However, what do you observe in the current plot? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    'Y': Y,\n",
    "    'Y_hat1': Y_hat1\n",
    "})\n",
    "\n",
    "layer1 = alt.Chart(source).mark_circle(size=1).encode(\n",
    "    x='Y',\n",
    "    y='Y_hat1'\n",
    ").properties(\n",
    "    title='Y VS Y_hat1'\n",
    ")\n",
    "\n",
    "layer2 = alt.Chart(source).mark_line(size=1).encode(\n",
    "    x='Y',\n",
    "    y='Y',\n",
    "    color = alt.value(\"red\")\n",
    ")\n",
    "\n",
    "layer1 + layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "For part 1, we only used the quantitative features `carat`, `depth`, `table`. As you can see from Question 1(e), the loss seems to be big. Is there a way to fit a better model by incorporating other features?\n",
    "\n",
    "In this second part of the lab, we explore incorporating qualitative features into our model.\n",
    "\n",
    "Recall our dataframe looks like the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only incorporated information about `carat`, `depth`, `table` in our previous features. Do `cut`, `color`, and `clarity` matter when it comes to predicting the prices of the diamonds?\n",
    "\n",
    "Based on this online article https://www.pricescope.com/diamond-prices, these characteristics should matter! So let's try to incoporate these into our model!\n",
    "\n",
    "Recall from the lecture, to include qualitative variables as features, we may use one-hot encoding. The idea of one-hot encoding is to vectorize the variables with 1's and 0's. For example, suppose we have a qualitative variable `smoking` and the variable can take on either 'smoker' or 'non-smoker' like what we show below:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "          <th></th>\n",
    "      <th>smoking</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <th>smoker</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <th>non-smoker</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <th>smoker</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <th>non-smoker</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <th>non-smoker</th>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "After one-hot encoding, the resulting dataframe will look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "          <th></th>\n",
    "      <th>smoker</th>\n",
    "      <th>non-smoker</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <th>1</th>\n",
    "      <th>0</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <th>0</th>\n",
    "      <th>1</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <th>1</th>\n",
    "      <th>0</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <th>0</th>\n",
    "      <th>1</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <th>0</th>\n",
    "      <th>1</th>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "For this lab, we will use the [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) method from `sklearn` package to implement one-hot encoding.\n",
    "\n",
    "Let's first examine how the model will behave if we include the `cut` feature. In the cell below, we created a new dataframe `X_char_w_cut` which adds one more column `cut` to the features defined in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_with_cut = data[['carat', 'cut', 'depth', 'table']]\n",
    "add_bias(X_features_with_cut)\n",
    "X_features_with_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a \n",
    "In the cell below, complete the code so that `X_with_cut` is the new feature matrix after one-hot encoding. There are a few things we need to do:\n",
    "1. Review the notebook example in the lecture on how to convert a categorical variable into a one-hot encoding matrix.\n",
    "2. Adjust the index issue (Done for you already).\n",
    "3. Combine the other features (except cut), and the one-hot encoding matrix together to form `X_with_cut`. You can use `pd.concat`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: false\n",
    "points: 5\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# one-hot encoding \n",
    "\n",
    "\n",
    "cuts = ...\n",
    "\n",
    "encoder = DictVectorizer(sparse=False)\n",
    "cuts_df = pd.DataFrame(\n",
    "    data = ...\n",
    "    columns = ...\n",
    ")\n",
    "\n",
    "\n",
    "# adjusting the index inconsistency issue\n",
    "X_features_with_cut.reset_index(drop=True, inplace=True)\n",
    "cuts_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine the features together with pd.concat\n",
    "X_with_cut = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b\n",
    "Now please fit a linear model using our new covariate matrix `X`. Compute the average squared loss of the predictions. Compare this loss with the loss you computed in Question 1(e) without using the `cut` feature. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "manual: false\n",
    "points: 6\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the proportion that the loss decreases after incorporating the `cut` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 < loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    'Y': Y,\n",
    "    'Y_hat2': Y_hat2\n",
    "})\n",
    "\n",
    "layer1 = alt.Chart(source).mark_circle(size=1).encode(\n",
    "    x='Y',\n",
    "    y='Y_hat2'\n",
    ").properties(\n",
    "    title='Y VS Y_hat2'\n",
    ")\n",
    "\n",
    "layer2 = alt.Chart(source).mark_line(size=1).encode(\n",
    "    x='Y',\n",
    "    y='Y',\n",
    "    color = alt.value(\"red\")\n",
    ")\n",
    "\n",
    "layer1 + layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot looks similar to the earlier one we have. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2c\n",
    "In the cell below, we consider adding `color` and `clarity` as features. Please fill in the relevant code below to fit a model with the covariate matrix `X_features_with_cut_color_clarity`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "manual: false\n",
    "points: 6\n",
    "gradescope: show\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the columns 'carat', 'cut', 'color', 'clarity', 'depth', 'table'\n",
    "X_features_with_cut_color_clarity = data[['carat', 'cut', 'color', 'clarity', 'depth', 'table']] # Do not change this line\n",
    "add_bias(X_features_with_cut_color_clarity)\n",
    "\n",
    "cut_color_clarity = ...\n",
    "encoder = ...\n",
    "\n",
    "cut_color_clarity_df = pd.DataFrame(\n",
    "    data = ...\n",
    "    columns = ...\n",
    ")\n",
    "\n",
    "# adjusting the index inconsistency issue. Uncomment the following two lines \n",
    "X_features_with_cut_color_clarity.reset_index(drop=True, inplace=True)\n",
    "cut_color_clarity_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine the features together \n",
    "X_with_cut_color_clarity = ...\n",
    "...\n",
    "\n",
    "model3 = ...\n",
    "...\n",
    "Y_hat3 = ...\n",
    "loss3 = ...\n",
    "\n",
    "loss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare `loss3` with `loss2` to check if our model works better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss3 < loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    'Y': Y,\n",
    "    'Y_hat3': Y_hat3\n",
    "})\n",
    "\n",
    "layer1 = alt.Chart(source).mark_circle(size=1).encode(\n",
    "    x='Y',\n",
    "    y='Y_hat3'\n",
    ").properties(\n",
    "    title='Y VS Y_hat3'\n",
    ")\n",
    "\n",
    "layer2 = alt.Chart(source).mark_line(size=1).encode(\n",
    "    x='Y',\n",
    "    y='Y',\n",
    "    color = alt.value(\"red\")\n",
    ")\n",
    "\n",
    "layer1 + layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 \n",
    "Try coming up with more features to make the model perform even better! Some suggestions are: include a `log(carat)` feature with the logarithmic values of `carat` or the characteristics `x`, `y`, `z` in the feature set. Write your code in the cell below. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "manual: true\n",
    "points: 10\n",
    "gradescope: show\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You have completed this assignment. Hope you enjoyed it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Running Built-in Tests\n",
    "1. All tests are in `tests` directory\n",
    "1. Each python file in `tests` is a test\n",
    "1. `grader.check('testname')` runs test `'testname'`, e.g. `'q1'`\n",
    "1. `grader.check_all()` runs all visible tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Run built-in checks\n",
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pdf in classic notebook (does not work in JupyterLab)\n",
    "import nb2pdf\n",
    "nb2pdf.convert('lab8.ipynb')\n",
    "\n",
    "# To generate pdf using command-line, run in terminal,\n",
    "# nb2pdf lab8.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submission Checklist\n",
    "1. Check filename is 'lab8.ipynb'\n",
    "1. Save file to confirm all changes are on disk\n",
    "1. Run *Kernel > Restart & Run All* to execute all code from top to bottom\n",
    "1. Check `grader.check_all()` output\n",
    "1. Save file again to write any new output to disk\n",
    "1. Check generated pdf that all responses are displayed correctly\n",
    "1. Submit to Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
